# Alexa ChatGPT Skill - Versi√≥n Mejorada

Skill de Amazon Alexa para interactuar con m√∫ltiples modelos avanzados de IA conversacional en espa√±ol, usando voz. Soporta modelos gratuitos y premium de OpenAI, GitHub, OpenRouter y m√°s.

## ‚ú® Caracter√≠sticas Principales

- **Selecci√≥n aleatoria y fallback autom√°tico de proveedor/modelo**: Si un modelo falla, cambia autom√°ticamente a otro disponible sin interrumpir la conversaci√≥n.
- **Optimizado para espa√±ol**: Responde siempre en espa√±ol, con ejemplos y contexto latinoamericano.
- **Gesti√≥n inteligente de sesi√≥n**: Mantiene historial relevante y cambia de tema f√°cilmente.
- **Manejo robusto de errores**: Reintentos autom√°ticos, logs detallados y mensajes claros para el usuario.
- **F√°cil integraci√≥n y despliegue en AWS Lambda**.

## ü§ñ Proveedores y Modelos Soportados

La skill soporta decenas de modelos de IA conversacional. Puedes forzar el uso de cualquier modelo usando su nombre de proveedor (provider key) en la variable `FORCED_PROVIDER` de `config.py`.

**Lista de modelos y nombres de proveedor (actualizada a mayo 2025):**

| Proveedor      | Provider Key (FORCED_PROVIDER)                | Modelo (model)                                      |
|---------------|-----------------------------------------------|-----------------------------------------------------|
| **OpenAI**    | `openai`                                      | gpt-4.1-mini                                        |
|               | `openai_gpt4o_mini`                           | gpt-4o-mini                                         |
|               | `openai_o4_mini`                              | o4-mini                                             |
|               | `openai_o3_mini`                              | o3-mini                                             |
| **GitHub**    | `github`                                      | openai/gpt-4.1-mini                                 |
|               | `github_openai_o4_mini`                       | openai/o4-mini                                      |
|               | `github_openai_o3_mini`                       | openai/o3-mini                                      |
|               | `github_openai_gpt4o_mini`                    | openai/gpt-4o-mini                                  |
| **Gemini**    | `gemini_20`                                   | gemini-2.0-flash                                    |
| (Google)      | `gemini_25`                                   | gemini-2.5-flash-preview-05-20                      |
| **OpenRouter**| `openrouter`                                  | meta-llama/llama-4-maverick                         |
|               | `openrouter_llama_maverick`                   | meta-llama/llama-4-maverick:free                    |
|               | `openrouter_deepseek_r1`                      | deepseek/deepseek-r1                                |
|               | `openrouter_deepseek_r1_free`                 | deepseek/deepseek-r1:free                           |
|               | `openrouter_deepseek_r1_distill_llama_70b`    | deepseek/deepseek-r1-distill-llama-70b:free         |
|               | `openrouter_deepseek_r1_0528`                 | deepseek/deepseek-r1-0528                           |
|               | `openrouter_deepseek_r1_0528_free`            | deepseek/deepseek-r1-0528:free                      |
|               | `openrouter_deepseek_chimera`                 | tngtech/deepseek-r1t-chimera:free                   |
|               | `openrouter_deepseek_chat_v3`                 | deepseek/deepseek-chat-v3-0324                      |
|               | `openrouter_deepseek_chat_v3_free`            | deepseek/deepseek-chat-v3-0324:free                 |
|               | `openrouter_qwen3_235b`                       | qwen/qwen3-235b-a22b                                |
|               | `openrouter_qwen3_235b_free`                  | qwen/qwen3-235b-a22b:free                           |
|               | `openrouter_qwen_qwq`                         | qwen/qwq-32b                                        |
|               | `openrouter_qwen_qwq_free`                    | qwen/qwq-32b:free                                   |
|               | `openrouter_microsoft_mai`                    | microsoft/mai-ds-r1:free                            |
|               | `openrouter_openai_gpt41_mini`                | openai/gpt-4.1-mini                                 |
|               | `openrouter_openai_gpt4o_mini`                | openai/gpt-4o-mini                                  |
|               | `openrouter_openai_o4_mini`                   | openai/o4-mini                                      |
|               | `openrouter_openai_o3_mini`                   | openai/o3-mini                                      |
|               | `openrouter_google_gemini_20`                 | google/gemini-2.0-flash-001                         |
|               | `openrouter_google_gemini_25`                 | google/gemini-2.5-flash-preview-05-20               |
|               | `openrouter_nvidia_llama31_nemotron_ultra_253b_free` | nvidia/llama-3.1-nemotron-ultra-253b-v1:free |
|               | `openrouter_meta_llama33_70b_instruct_free`   | meta-llama/llama-3.3-70b-instruct:free              |
|               | `openrouter_meta_llama31_405b_free`           | meta-llama/llama-3.1-405b:free                      |
| **Cerebras**  | `cerebras`                                    | llama-4-scout-17b-16e-instruct                      |
|               | `cerebras_llama4_scout`                       | llama-4-scout-17b-16e-instruct                      |
|               | `cerebras_llama33_70b`                        | llama-3.3-70b                                       |
|               | `cerebras_qwen3_32b`                          | qwen-3-32b                                          |
|               | `cerebras_deepseek_r1_distill_llama_70b`      | deepseek-r1-distill-llama-70b                       |
| **DeepInfra** | `deepinfra_deepseek_v3`                       | deepseek-ai/DeepSeek-V3-0324                        |
|               | `deepinfra_qwen_qwq_32b`                      | Qwen/QwQ-32B                                        |
|               | `deepinfra_deepseek_r1`                       | deepseek-ai/DeepSeek-R1                             |
|               | `deepinfra_llama4_maverick`                   | meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8   |
|               | `deepinfra_qwen3_32b`                         | Qwen/Qwen3-32B                                      |
|               | `deepinfra_deepseek_r1_0528`                  | deepseek-ai/DeepSeek-R1-0528                        |
| **Moonshot**  | `moonshot`                                    | moonshot-v1-8k                                      |

> **Nota:** El nombre de proveedor (provider key) es el que debes usar en `FORCED_PROVIDER` si quieres forzar un modelo espec√≠fico.

Consulta siempre `lambda/lambda_function.py` para la lista m√°s actualizada de modelos soportados y sus nombres.

## üîë Configuraci√≥n de API Keys

> **Nota:** Si no configuras al menos una API key v√°lida, la skill no funcionar√°.
> 
> **Importante:** Si dejas el valor por defecto (por ejemplo, `"OPENAI_API_KEY"`, `""` o similar) en alguna de las variables `API_KEY`, `GITHUB_TOKEN`, `OPENROUTER_API_KEY` o `CEREBRAS_API_KEY` en `lambda/config.py`, los modelos de ese proveedor NO estar√°n disponibles para la skill. Solo se consideran los proveedores cuya clave ha sido configurada correctamente.

Coloca tus claves en las variables `API_KEY`, `GITHUB_TOKEN`, `OPENROUTER_API_KEY` y/o `CEREBRAS_API_KEY` seg√∫n los proveedores que quieras usar.

Opcionalmente, puedes forzar el uso de un proveedor espec√≠fico configurando la variable `FORCED_PROVIDER` en `lambda/config.py` (por ejemplo: `'openai'`, `'cerebras_llama4_scout'`, etc.).

## üìÅ Estructura del Proyecto

```
alexa-chatgpt/
‚îú‚îÄ‚îÄ skill.json
‚îú‚îÄ‚îÄ interactionModels/
‚îÇ   ‚îî‚îÄ‚îÄ custom/
‚îÇ       ‚îî‚îÄ‚îÄ es-MX.json
‚îú‚îÄ‚îÄ lambda/
‚îÇ   ‚îú‚îÄ‚îÄ lambda_function.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Instalaci√≥n y Despliegue

1. **Instala dependencias:**
   ```bash
   cd lambda
   pip install -r requirements.txt
   ```
2. **Configura tus API keys:**
   - Edita el archivo `lambda/config.py` y coloca tus claves en las variables `API_KEY`, `GITHUB_TOKEN`, `OPENROUTER_API_KEY` y/o `CEREBRAS_API_KEY` seg√∫n los proveedores que quieras usar.
   - Para forzar un proveedor espec√≠fico, asigna su nombre a la variable `FORCED_PROVIDER` en el mismo archivo. Ejemplo:
     ```python
     FORCED_PROVIDER = 'cerebras_llama4_scout'
     ```
3. **Despliega en AWS Lambda:**
   - Comprime el contenido de `lambda/` (no la carpeta, solo los archivos).
   - Sube el ZIP a tu funci√≥n Lambda.
   - Configura las variables de entorno.
4. **Configura la Alexa Skill:**
   - Importa `skill.json` e `interactionModels/custom/es-MX.json` en el Developer Console de Alexa.
   - Conecta la skill con tu funci√≥n Lambda.

## Personalizaci√≥n de pa√≠s y tono

Puedes personalizar el pa√≠s y el tono de las respuestas editando el archivo `config.py`:

```python
COUNTRY = "Colombia"   # Cambia por el pa√≠s que desees
TONE = "colombiano"    # Cambia por el tono o gentilicio adecuado (ej: mexicano, argentino, chileno)
```

Esto har√° que la skill adapte sus respuestas y ejemplos culturales al pa√≠s y tono que configures.

## üß† L√≥gica de Proveedor y Fallback

- Al iniciar sesi√≥n, se selecciona aleatoriamente un proveedor/modelo disponible (a menos que uses `FORCED_PROVIDER`).
- Si un proveedor falla (timeout, error, etc.), la skill intenta autom√°ticamente con otros modelos disponibles (hasta 3 intentos por pregunta).
- Si defines `FORCED_PROVIDER`, siempre se usar√° ese proveedor para todas las consultas.
- El historial de conversaci√≥n se mantiene por sesi√≥n (m√°ximo 8 interacciones recientes para optimizar tokens).
- Puedes reiniciar el tema diciendo "nuevo tema" o "empezar de nuevo".

## üìù Ejemplo de Uso

```
Usuario: "Alexa, abre modo chat"
Alexa: "¬°Hola! Soy tu asistente inteligente. Puedes preguntarme sobre cualquier tema..."

Usuario: "Expl√≠came qu√© es la inteligencia artificial"
Alexa: "La inteligencia artificial es la capacidad de las m√°quinas para imitar procesos cognitivos humanos..."

Usuario: "Nuevo tema"
Alexa: "¬°Perfecto! Empecemos con un tema nuevo. ¬øSobre qu√© te gustar√≠a conversar ahora?"

Usuario: "H√°blame sobre la cocina mexicana"
Alexa: "La cocina mexicana es una de las m√°s ricas y diversas del mundo..."
```

## üõ°Ô∏è Seguridad

- **Nunca subas tus API keys a repositorios p√∫blicos.**
- Usa variables de entorno en AWS Lambda para producci√≥n.
- Para mayor seguridad, considera usar AWS Secrets Manager.
- Si compartes el c√≥digo, elimina o reemplaza las claves en `.env.example`.

## üõ†Ô∏è Troubleshooting / Errores Comunes

- **Timeout:** El modelo puede estar saturado. Intenta de nuevo o usa otro proveedor.
- **Problemas de conexi√≥n:** Verifica tu red o la validez de las API keys.
- **Respuestas vac√≠as:** Puede ser un error temporal del modelo. Intenta otra pregunta o espera unos minutos.
- **No hay proveedores disponibles:** Aseg√∫rate de tener al menos una API key v√°lida configurada.

Consulta los logs de CloudWatch (AWS Lambda) para detalles de errores y debugging.

## ‚ûï Agregar nuevos modelos/proveedores

Para agregar un nuevo modelo, edita el diccionario `PROVIDERS` en `lambda_function.py` siguiendo el formato de los modelos existentes. Aseg√∫rate de:
- Definir el nombre, URL, modelo, headers y c√≥mo obtener la API key.
- Agregar el nombre del proveedor a la lista `available_providers` si la key est√° configurada.

## ü§ù Contribuciones

1. Haz fork del repositorio
2. Crea una rama para tu feature
3. Implementa tus cambios y agrega tests si es necesario
4. Haz un Pull Request

---

## üìã TODO / Mejoras Futuras

- [ ] Implementar cache de respuestas para consultas similares
- [ ] Agregar soporte para m√°s idiomas
- [ ] An√°lisis de sentimiento para ajustar respuestas
- [ ] M√©tricas de uso por proveedor
- [ ] Rate limiting
- [ ] Soporte para streaming de respuestas
- [ ] Dashboard de monitoreo
