# Alexa ChatGPT Skill - VersiÃ³n Mejorada

Skill de Amazon Alexa para interactuar con mÃºltiples modelos avanzados de IA conversacional en espaÃ±ol, usando voz. Soporta modelos gratuitos y premium de OpenAI, GitHub, OpenRouter y mÃ¡s.

## âœ¨ CaracterÃ­sticas Principales

- **SelecciÃ³n aleatoria y fallback automÃ¡tico de proveedor/modelo**: Si un modelo falla, cambia automÃ¡ticamente a otro disponible sin interrumpir la conversaciÃ³n.
- **Optimizado para espaÃ±ol**: Responde siempre en espaÃ±ol, con ejemplos y contexto latinoamericano.
- **GestiÃ³n inteligente de sesiÃ³n**: Mantiene historial relevante y cambia de tema fÃ¡cilmente.
- **Manejo robusto de errores**: Reintentos automÃ¡ticos, logs detallados y mensajes claros para el usuario.
- **FÃ¡cil integraciÃ³n y despliegue en AWS Lambda**.

## ğŸ¤– Proveedores y Modelos Soportados

La skill soporta decenas de modelos de IA conversacional. Puedes forzar el uso de cualquier modelo usando su nombre de proveedor (provider key) en la variable `FORCED_PROVIDER` de `config.py`.

**Lista de modelos y nombres de proveedor (actualizada a mayo 2025):**

| Proveedor      | Provider Key (FORCED_PROVIDER)                | Modelo (model)                                      |
|---------------|-----------------------------------------------|-----------------------------------------------------|
| **OpenAI**    | `openai`                                      | gpt-4.1-mini                                        |
|               | `openai_gpt4o_mini`                           | gpt-4o-mini                                         |
|               | `openai_o4_mini`                              | o4-mini                                             |
|               | `openai_o3_mini`                              | o3-mini                                             |
| **GitHub**    | `github`                                      | openai/gpt-4.1-mini                                 |
|               | `github_openai_o4_mini`                       | openai/o4-mini                                      |
|               | `github_openai_o3_mini`                       | openai/o3-mini                                      |
|               | `github_openai_gpt4o_mini`                    | openai/gpt-4o-mini                                  |
| **Gemini**    | `gemini_20`                                   | gemini-2.0-flash                                    |
| (Google)      | `gemini_25`                                   | gemini-2.5-flash-preview-05-20                      |
| **OpenRouter**| `openrouter`                                  | meta-llama/llama-4-maverick                         |
|               | `openrouter_llama_maverick`                   | meta-llama/llama-4-maverick:free                    |
|               | `openrouter_deepseek_r1`                      | deepseek/deepseek-r1                                |
|               | `openrouter_deepseek_r1_free`                 | deepseek/deepseek-r1:free                           |
|               | `openrouter_deepseek_r1_distill_llama_70b`    | deepseek/deepseek-r1-distill-llama-70b:free         |
|               | `openrouter_deepseek_r1_0528`                 | deepseek/deepseek-r1-0528                           |
|               | `openrouter_deepseek_r1_0528_free`            | deepseek/deepseek-r1-0528:free                      |
|               | `openrouter_deepseek_chimera`                 | tngtech/deepseek-r1t-chimera:free                   |
|               | `openrouter_qwen3_235b`                       | qwen/qwen3-235b-a22b                                |
|               | `openrouter_qwen3_235b_free`                  | qwen/qwen3-235b-a22b:free                           |
|               | `openrouter_qwen_qwq`                         | qwen/qwq-32b                                        |
|               | `openrouter_qwen_qwq_free`                    | qwen/qwq-32b:free                                   |
|               | `openrouter_microsoft_mai`                    | microsoft/mai-ds-r1:free                            |
|               | `openrouter_deepseek_chat_v3`                 | deepseek/deepseek-chat-v3-0324                      |
|               | `openrouter_deepseek_chat_v3_free`            | deepseek/deepseek-chat-v3-0324:free                 |
|               | `openrouter_openai_gpt41_mini`                | openai/gpt-4.1-mini                                 |
|               | `openrouter_google_gemini_20`                 | google/gemini-2.0-flash-001                         |
|               | `openrouter_google_gemini_25`                 | google/gemini-2.5-flash-preview-05-20               |
| **Cerebras**  | `cerebras`                                    | llama-4-scout-17b-16e-instruct                      |
|               | `cerebras_llama4_scout`                       | llama-4-scout-17b-16e-instruct                      |
|               | `cerebras_llama33_70b`                        | llama-3.3-70b                                       |
|               | `cerebras_qwen3_32b`                          | qwen-3-32b                                          |
|               | `cerebras_deepseek_r1_distill_llama_70b`      | deepseek-r1-distill-llama-70b                       |
| **DeepInfra** | `deepinfra_deepseek_v3`                       | deepseek-ai/DeepSeek-V3-0324                        |
|               | `deepinfra_qwen_qwq_32b`                      | Qwen/QwQ-32B                                        |
|               | `deepinfra_deepseek_r1`                       | deepseek-ai/DeepSeek-R1                             |
|               | `deepinfra_llama4_maverick`                   | meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8   |
|               | `deepinfra_qwen3_32b`                         | Qwen/Qwen3-32B                                      |
|               | `deepinfra_deepseek_r1_0528`                  | deepseek-ai/DeepSeek-R1-0528                        |
| **Moonshot**  | `moonshot`                                    | moonshot-v1-8k                                      |

> **Nota:** El nombre de proveedor (provider key) es el que debes usar en `FORCED_PROVIDER` si quieres forzar un modelo especÃ­fico.

Consulta siempre `lambda/lambda_function.py` para la lista mÃ¡s actualizada de modelos soportados y sus nombres.

## ğŸ”‘ ConfiguraciÃ³n de API Keys

> **Nota:** Si no configuras al menos una API key vÃ¡lida, la skill no funcionarÃ¡.

Coloca tus claves en las variables `API_KEY`, `GITHUB_TOKEN`, `OPENROUTER_API_KEY` y/o `CEREBRAS_API_KEY` segÃºn los proveedores que quieras usar.

Opcionalmente, puedes forzar el uso de un proveedor especÃ­fico configurando la variable `FORCED_PROVIDER` en `lambda/config.py` (por ejemplo: `'openai'`, `'cerebras_llama4_scout'`, etc.).

## ğŸ“ Estructura del Proyecto

```
alexa-chatgpt/
â”œâ”€â”€ skill.json
â”œâ”€â”€ interactionModels/
â”‚   â””â”€â”€ custom/
â”‚       â””â”€â”€ es-MX.json
â”œâ”€â”€ lambda/
â”‚   â”œâ”€â”€ lambda_function.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ InstalaciÃ³n y Despliegue

1. **Instala dependencias:**
   ```bash
   cd lambda
   pip install -r requirements.txt
   ```
2. **Configura tus API keys:**
   - Edita el archivo `lambda/config.py` y coloca tus claves en las variables `API_KEY`, `GITHUB_TOKEN`, `OPENROUTER_API_KEY` y/o `CEREBRAS_API_KEY` segÃºn los proveedores que quieras usar.
   - Para forzar un proveedor especÃ­fico, asigna su nombre a la variable `FORCED_PROVIDER` en el mismo archivo. Ejemplo:
     ```python
     FORCED_PROVIDER = 'cerebras_llama4_scout'
     ```
3. **Despliega en AWS Lambda:**
   - Comprime el contenido de `lambda/` (no la carpeta, solo los archivos).
   - Sube el ZIP a tu funciÃ³n Lambda.
   - Configura las variables de entorno.
4. **Configura la Alexa Skill:**
   - Importa `skill.json` e `interactionModels/custom/es-MX.json` en el Developer Console de Alexa.
   - Conecta la skill con tu funciÃ³n Lambda.

## PersonalizaciÃ³n de paÃ­s y tono

Puedes personalizar el paÃ­s y el tono de las respuestas editando el archivo `config.py`:

```python
COUNTRY = "Colombia"   # Cambia por el paÃ­s que desees
TONE = "colombiano"    # Cambia por el tono o gentilicio adecuado (ej: mexicano, argentino, chileno)
```

Esto harÃ¡ que la skill adapte sus respuestas y ejemplos culturales al paÃ­s y tono que configures.

## ğŸ§  LÃ³gica de Proveedor y Fallback

- Al iniciar sesiÃ³n, se selecciona aleatoriamente un proveedor/modelo disponible (a menos que uses `FORCED_PROVIDER`).
- Si un proveedor falla (timeout, error, etc.), la skill intenta automÃ¡ticamente con otros modelos disponibles (hasta 3 intentos por pregunta).
- Si defines `FORCED_PROVIDER`, siempre se usarÃ¡ ese proveedor para todas las consultas.
- El historial de conversaciÃ³n se mantiene por sesiÃ³n (mÃ¡ximo 8 interacciones recientes para optimizar tokens).
- Puedes reiniciar el tema diciendo "nuevo tema" o "empezar de nuevo".

## ğŸ“ Ejemplo de Uso

```
Usuario: "Alexa, abre modo chat"
Alexa: "Â¡Hola! Soy tu asistente inteligente. Puedes preguntarme sobre cualquier tema..."

Usuario: "ExplÃ­came quÃ© es la inteligencia artificial"
Alexa: "La inteligencia artificial es la capacidad de las mÃ¡quinas para imitar procesos cognitivos humanos..."

Usuario: "Nuevo tema"
Alexa: "Â¡Perfecto! Empecemos con un tema nuevo. Â¿Sobre quÃ© te gustarÃ­a conversar ahora?"

Usuario: "HÃ¡blame sobre la cocina mexicana"
Alexa: "La cocina mexicana es una de las mÃ¡s ricas y diversas del mundo..."
```

## ğŸ›¡ï¸ Seguridad

- **Nunca subas tus API keys a repositorios pÃºblicos.**
- Usa variables de entorno en AWS Lambda para producciÃ³n.
- Para mayor seguridad, considera usar AWS Secrets Manager.
- Si compartes el cÃ³digo, elimina o reemplaza las claves en `.env.example`.

## ğŸ› ï¸ Troubleshooting / Errores Comunes

- **Timeout:** El modelo puede estar saturado. Intenta de nuevo o usa otro proveedor.
- **Problemas de conexiÃ³n:** Verifica tu red o la validez de las API keys.
- **Respuestas vacÃ­as:** Puede ser un error temporal del modelo. Intenta otra pregunta o espera unos minutos.
- **No hay proveedores disponibles:** AsegÃºrate de tener al menos una API key vÃ¡lida configurada.

Consulta los logs de CloudWatch (AWS Lambda) para detalles de errores y debugging.

## â• Agregar nuevos modelos/proveedores

Para agregar un nuevo modelo, edita el diccionario `PROVIDERS` en `lambda_function.py` siguiendo el formato de los modelos existentes. AsegÃºrate de:
- Definir el nombre, URL, modelo, headers y cÃ³mo obtener la API key.
- Agregar el nombre del proveedor a la lista `available_providers` si la key estÃ¡ configurada.

## ğŸ¤ Contribuciones

1. Haz fork del repositorio
2. Crea una rama para tu feature
3. Implementa tus cambios y agrega tests si es necesario
4. Haz un Pull Request

---

## ğŸ“‹ TODO / Mejoras Futuras

- [ ] Implementar cache de respuestas para consultas similares
- [ ] Agregar soporte para mÃ¡s idiomas
- [ ] AnÃ¡lisis de sentimiento para ajustar respuestas
- [ ] MÃ©tricas de uso por proveedor
- [ ] Rate limiting
- [ ] Soporte para streaming de respuestas
- [ ] Dashboard de monitoreo
